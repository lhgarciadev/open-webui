# ==============================================================================
# Cognitia White-Label Environment Configuration
# ==============================================================================
# Copy this file to .env.whitelabel and customize for your deployment
# Usage: docker-compose --env-file .env.whitelabel -f docker-compose.whitelabel.yaml up -d

# ==============================================================================
# BRANDING
# ==============================================================================
BRAND_NAME=Cognitia

# ==============================================================================
# BUILD SETTINGS
# ==============================================================================
VERSION=1.0.0
REGISTRY=local
BUILD_HASH=dev

# GPU Support (set to true for NVIDIA CUDA)
USE_CUDA=false

# Include Ollama in the container
USE_OLLAMA=false

# Slim build (no pre-downloaded models)
USE_SLIM=false

# ==============================================================================
# RUNTIME SETTINGS
# ==============================================================================
# Port mapping (host:container is PORT:8080)
PORT=3000

# Secret key for JWT tokens (required, generate with: openssl rand -hex 32)
SECRET_KEY=<define-in-secret-manager>

# User registration
ENABLE_SIGNUP=true
DEFAULT_USER_ROLE=pending

# ==============================================================================
# LLM PROVIDERS
# ==============================================================================
# Ollama connection (default uses the ollama service in docker-compose)
OLLAMA_URL=http://ollama:11434

# OpenAI API (optional)
OPENAI_API_BASE_URL=
OPENAI_API_KEY=

# Presentations and builtin tools rely on native function calling mode.
# For existing deployments, set to default if your selected model lacks native function calling support.
DEFAULT_FUNCTION_CALLING_MODE=native

# ==============================================================================
# ADDITIONAL PROVIDERS (optional)
# ==============================================================================
# Anthropic API
# ANTHROPIC_API_KEY=

# Azure OpenAI
# AZURE_OPENAI_API_KEY=
# AZURE_OPENAI_ENDPOINT=
# AZURE_OPENAI_DEPLOYMENT=

# Google AI (Gemini)
# GOOGLE_API_KEY=

# ==============================================================================
# PERSISTENCE STACK (recommended for production)
# ==============================================================================
# Enable automatic schema migrations at startup
ENABLE_DB_MIGRATIONS=true

# PostgreSQL (use provider secrets, do not commit credentials)
# Example with docker-compose.persistence.yaml:
# POSTGRES_DB=cognitia
# POSTGRES_USER=cognitia_app
# POSTGRES_PASSWORD=<from-secret-manager>
# DATABASE_URL=postgresql://cognitia_app:<from-secret-manager>@postgres:5432/cognitia
DATABASE_URL=

# Redis for sessions/cache/realtime coordination (optional but recommended)
# REDIS_URL=redis://redis:6379/0
REDIS_URL=

# ==============================================================================
# SECURITY (optional)
# ==============================================================================
# Enable HTTPS redirect
# ENABLE_HTTPS_REDIRECT=false

# CORS settings
# CORS_ALLOW_ORIGINS=*
