# Fase 2.2 - Validar Configuración de ZeroGPU

## Objetivo

Verificar que ZeroGPU está activo y funcionando correctamente.

## Prompt de Validación

```
Valida que ZeroGPU está correctamente configurado:

1. VERIFICAR HARDWARE EN UI:

   # Abrir Space (reemplaza TU_USUARIO)
   # https://huggingface.co/spaces/TU_USUARIO/cognitia-ollama

   # En la parte superior debe mostrar:
   # - Hardware: ZeroGPU (o zero-a10g)
   # - Status: Running

2. VERIFICAR LOGS DE GPU:

   # Click en "Logs" del Space
   # Buscar indicadores de GPU:

   # Positivos (alguno de estos):
   # - "CUDA available: True"
   # - "GPU: NVIDIA"
   # - "Running on GPU"
   # - No errores de CUDA

   # Negativos (no deberían aparecer):
   # - "CUDA not available"
   # - "Running on CPU"
   # - "No GPU found"

3. TEST DE API (básico):

   # Probar que el Space responde (reemplaza TU_USUARIO)
   curl -s https://TU_USUARIO-cognitia-ollama.hf.space/api/tags | head -20

   # Respuesta esperada (JSON con modelos):
   # {"models":[...]}

   # Si está descargando modelos, puede tardar

4. TEST DE INFERENCIA:

   # Generar una respuesta simple
   time curl -s https://TU_USUARIO-cognitia-ollama.hf.space/api/generate \
     -H "Content-Type: application/json" \
     -d '{"model": "phi3", "prompt": "Di hola", "stream": false}' | head -50

   # Con GPU: < 2 segundos
   # Sin GPU: > 5 segundos

5. VERIFICAR CUOTA:

   # Ver cuota en HF
   # https://huggingface.co/settings/billing

   # Sección "ZeroGPU Usage"
   # Debe mostrar:
   # - Cuota disponible (%)
   # - Uso del día

6. COMPARAR LATENCIA:

   # Ejecutar 3 veces y promediar
   for i in 1 2 3; do
     echo "Test $i:"
     time curl -s https://TU_USUARIO-cognitia-ollama.hf.space/api/generate \
       -H "Content-Type: application/json" \
       -d '{"model": "phi3", "prompt": "Hola", "stream": false}' > /dev/null
     echo "---"
   done

   # Esperado con ZeroGPU: 0.5-1.5 segundos
   # Si es > 3 segundos: posible CPU fallback

Resultado esperado:
- Hardware muestra ZeroGPU activo
- Logs sin errores de GPU
- Latencia < 2 segundos
- Cuota disponible
```

## Checklist de Validación

```
HARDWARE
[ ] UI muestra ZeroGPU
[ ] Status: Running
[ ] Sin errores de GPU en logs

API
[ ] /api/tags responde con modelos
[ ] /api/generate funciona
[ ] Latencia < 2 segundos

CUOTA
[ ] Cuota visible en billing
[ ] Cuota > 0%
```

## Criterios de Éxito

| Criterio     | Esperado | Crítico |
| ------------ | -------- | ------- |
| Hardware     | ZeroGPU  | Sí      |
| Status       | Running  | Sí      |
| Latencia     | < 2s     | Sí      |
| API responde | Sí       | Sí      |
| Cuota        | > 0%     | Sí      |

## Métricas de Performance

| Métrica    | CPU (anterior) | ZeroGPU (esperado) |
| ---------- | -------------- | ------------------ |
| Latencia   | 2-5s           | 0.5-1.5s           |
| Tokens/s   | 5-10           | 50-100             |
| Cold start | 30-60s         | 10-30s             |

## Si Falla

### Latencia alta (>3s)

```bash
# Verificar que no está en CPU fallback
# Ver logs del Space
# Buscar "Running on CPU" → Problema de GPU

# Reiniciar Space
# Settings → Factory reboot
```

### API no responde

```bash
# Verificar que el Space está Running
# Si está Sleeping, hacer request para despertar
curl https://TU_USUARIO-cognitia-ollama.hf.space/api/tags

# Esperar 30 segundos y reintentar
```

### Cuota agotada (0%)

```bash
# Opciones:
# 1. Esperar reset diario (24h)
# 2. Upgrade a PRO: https://huggingface.co/pricing
# 3. Continuar con CPU (más lento)
```

### GPU errors en logs

```bash
# Posibles causas:
# - Modelo muy grande para VRAM
# - Conflicto de CUDA versions

# Solución: usar modelos más pequeños
# qwen2.5:7b → phi3 (más pequeño)
```

## Siguiente Paso

Si todos los criterios pasan: Continuar a [3.1-models-ejecutar.md](./3.1-models-ejecutar.md)

Si falla la GPU: Revisar troubleshooting o contactar HF support.
