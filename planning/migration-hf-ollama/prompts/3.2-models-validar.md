# Fase 3.2 - Validar Modelos Descargados

## Objetivo
Verificar que todos los modelos funcionan correctamente y medir su rendimiento.

## Prompt de Validación

```
Valida que los modelos están funcionando correctamente:

1. LISTAR TODOS LOS MODELOS:

   # Obtener lista completa (reemplaza TU_USUARIO)
   curl -s https://TU_USUARIO-cognitia-ollama.hf.space/api/tags | jq '.models[] | {name: .name, size: .size, modified: .modified_at}'

   # Debe mostrar al menos 3 modelos:
   # - qwen2.5:7b
   # - phi3
   # - codellama:7b

2. BENCHMARK DE LATENCIA:

   # Script de benchmark
   SPACE_URL="https://TU_USUARIO-cognitia-ollama.hf.space"

   echo "=== BENCHMARK DE LATENCIA ==="
   for model in "phi3" "qwen2.5:7b" "codellama:7b"; do
     echo ""
     echo "Modelo: $model"
     total=0
     for i in 1 2 3; do
       start=$(date +%s.%N)
       curl -s "$SPACE_URL/api/generate" \
         -H "Content-Type: application/json" \
         -d "{\"model\": \"$model\", \"prompt\": \"Hola\", \"stream\": false}" > /dev/null
       end=$(date +%s.%N)
       elapsed=$(echo "$end - $start" | bc)
       echo "  Run $i: ${elapsed}s"
       total=$(echo "$total + $elapsed" | bc)
     done
     avg=$(echo "scale=2; $total / 3" | bc)
     echo "  Promedio: ${avg}s"
   done

3. TEST DE CALIDAD:

   # Test de razonamiento (qwen2.5:7b)
   echo "=== Test Razonamiento ==="
   curl -s "$SPACE_URL/api/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "model": "qwen2.5:7b",
       "prompt": "Si tengo 3 manzanas y como 1, ¿cuántas me quedan? Responde solo con el número.",
       "stream": false
     }' | jq -r '.response'
   # Esperado: "2"

   # Test de código (codellama:7b)
   echo "=== Test Código ==="
   curl -s "$SPACE_URL/api/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "model": "codellama:7b",
       "prompt": "Write a Python function called add that takes two numbers and returns their sum. Only the code, no explanation.",
       "stream": false
     }' | jq -r '.response'
   # Esperado: función válida de Python

   # Test de velocidad (phi3)
   echo "=== Test Velocidad ==="
   curl -s "$SPACE_URL/api/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "model": "phi3",
       "prompt": "Capital de Francia, una palabra:",
       "stream": false
     }' | jq -r '.response'
   # Esperado: "París" o similar

4. VERIFICAR CHAT API:

   # Test de conversación multi-turno
   curl -s "$SPACE_URL/api/chat" \
     -H "Content-Type: application/json" \
     -d '{
       "model": "qwen2.5:7b",
       "messages": [
         {"role": "user", "content": "Mi nombre es Juan"},
         {"role": "assistant", "content": "Hola Juan, mucho gusto"},
         {"role": "user", "content": "¿Cómo me llamo?"}
       ],
       "stream": false
     }' | jq -r '.message.content'
   # Esperado: "Juan" o mención del nombre

5. RESUMEN DE MÉTRICAS:

   echo "=== RESUMEN ==="
   echo "Modelos: $(curl -s $SPACE_URL/api/tags | jq '.models | length')"
   echo "Latencia phi3: <1s (esperado)"
   echo "Latencia qwen2.5: <2s (esperado)"
   echo "Latencia codellama: <2s (esperado)"

Resultado esperado:
- 3+ modelos disponibles
- Latencia promedio < 2s
- Respuestas coherentes
- Chat API funciona
```

## Checklist de Validación

```
MODELOS
[ ] qwen2.5:7b presente y funciona
[ ] phi3 presente y funciona
[ ] codellama:7b presente y funciona

LATENCIA
[ ] phi3 < 1.5s promedio
[ ] qwen2.5:7b < 2s promedio
[ ] codellama:7b < 2s promedio

CALIDAD
[ ] Respuestas coherentes
[ ] Código válido de codellama
[ ] Razonamiento correcto de qwen2.5

API
[ ] /api/generate funciona
[ ] /api/chat funciona
[ ] /api/tags lista modelos
```

## Criterios de Éxito

| Criterio | Esperado | Crítico |
|----------|----------|---------|
| Modelos | >= 3 | Sí |
| Latencia promedio | < 2s | Sí |
| Respuestas coherentes | Sí | Sí |
| API generate | Funciona | Sí |
| API chat | Funciona | Sí |

## Métricas Esperadas

| Modelo | Latencia | Tokens/s | Calidad |
|--------|----------|----------|---------|
| phi3 | 0.5-1.5s | 60-100 | ⭐⭐⭐⭐ |
| qwen2.5:7b | 1-2s | 40-70 | ⭐⭐⭐⭐⭐ |
| codellama:7b | 1-2s | 40-70 | ⭐⭐⭐⭐ |

## Si Falla

### Latencia alta (>3s)
```bash
# Posibles causas:
# 1. GPU no activa → Verificar Fase 2
# 2. Modelo muy grande → Usar modelo más pequeño
# 3. Space en sleep → Esperar cold start

# Reintentar después de 30s
```

### Respuestas incoherentes
```bash
# Posibles causas:
# 1. Modelo corrupto → Reiniciar Space
# 2. Prompt mal formado → Verificar JSON
# 3. Timeout → Aumentar longitud de respuesta
```

### API error 500
```bash
# Ver logs del Space
# Buscar errores específicos
# Posible: OOM (out of memory) → Usar modelo más pequeño
```

## Siguiente Paso

Si todos los criterios pasan: Continuar a [4.1-connect-ejecutar.md](./4.1-connect-ejecutar.md)

Si falla algún modelo: Corregir y repetir validación.
