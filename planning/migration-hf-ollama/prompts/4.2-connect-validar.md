# Fase 4.2 - Validar Conexión de Cognitia

## Objetivo

Verificar que Cognitia está correctamente conectado al Space de HF y funciona end-to-end.

## Prompt de Validación

```
Valida la conexión entre Cognitia y el Space de HF:

1. VERIFICAR VARIABLE EN RAILWAY:

   # Opción A - Dashboard
   # Railway Dashboard > Proyecto > Servicio > Variables
   # Verificar: OLLAMA_BASE_URL = https://TU_USUARIO-cognitia-ollama.hf.space

   # Opción B - CLI
   railway variables | grep OLLAMA

2. VERIFICAR LOGS DE COGNITIA:

   # Ver logs recientes
   railway logs --tail 50

   # Buscar:
   # - "Connected to Ollama"
   # - Sin errores de conexión
   # - Requests a la URL de HF

3. VERIFICAR UI - SETTINGS:

   a) Abrir https://cognitia-production.up.railway.app
   b) Login como admin
   c) Ir a Settings > Connections
   d) Verificar:
      - Ollama URL: https://TU_USUARIO-cognitia-ollama.hf.space
      - Status: Connected (verde)
      - Models: lista de modelos visible

4. VERIFICAR UI - SELECTOR DE MODELOS:

   a) Ir a la página principal de chat
   b) Click en selector de modelos
   c) Verificar que aparecen:
      - qwen2.5:7b
      - phi3
      - codellama:7b

5. TEST DE CHAT - MODELO RÁPIDO:

   a) Seleccionar modelo: phi3
   b) Enviar mensaje: "Hola, di tu nombre"
   c) Medir tiempo de respuesta
   d) Verificar respuesta coherente

   # Esperado: < 2 segundos

6. TEST DE CHAT - MODELO POTENTE:

   a) Seleccionar modelo: qwen2.5:7b
   b) Enviar mensaje: "Escribe una función Python para calcular factorial"
   c) Verificar código válido
   d) Medir tiempo de respuesta

   # Esperado: < 3 segundos, código correcto

7. TEST DE CHAT - CÓDIGO:

   a) Seleccionar modelo: codellama:7b
   b) Enviar mensaje: "Fix this JavaScript: const x = [1,2,3; console.log(x)"
   c) Verificar corrección del código

8. COMPARAR CON RAILWAY ANTERIOR:

   # Si aún tienes el servicio Ollama en Railway:
   # Notar diferencia de velocidad
   #
   # Railway CPU: 2-5 segundos
   # HF ZeroGPU: 0.5-2 segundos
   #
   # Mejora esperada: 2-5x más rápido

9. VERIFICAR MÚLTIPLES USUARIOS:

   a) Logout
   b) Login con otro usuario
   c) Verificar que también ve los modelos
   d) Enviar chat y verificar respuesta

Resultado esperado:
- Settings muestra URL de HF
- Modelos visibles en selector
- Chats funcionan correctamente
- Latencia < 3 segundos
- Múltiples usuarios pueden usar
```

## Checklist de Validación

```
RAILWAY
[ ] Variable OLLAMA_BASE_URL correcta
[ ] Logs sin errores de conexión
[ ] Servicio Running

COGNITIA UI
[ ] Settings muestra URL de HF
[ ] Conexión status: Connected
[ ] Modelos listados correctamente

CHAT
[ ] phi3 funciona (< 2s)
[ ] qwen2.5:7b funciona (< 3s)
[ ] codellama:7b funciona
[ ] Respuestas coherentes

USUARIOS
[ ] Admin puede usar
[ ] Otros usuarios pueden usar
[ ] Sin errores de permisos
```

## Criterios de Éxito

| Criterio         | Esperado    | Crítico |
| ---------------- | ----------- | ------- |
| Conexión         | Establecida | Sí      |
| Modelos visibles | 3+          | Sí      |
| Latencia phi3    | < 2s        | Sí      |
| Latencia qwen2.5 | < 3s        | Sí      |
| Multi-usuario    | Funciona    | Sí      |

## Métricas de Comparación

| Métrica  | Railway (antes) | HF (después) | Mejora |
| -------- | --------------- | ------------ | ------ |
| Latencia | 2-5s            | 0.5-2s       | 2-5x   |
| Modelos  | 1 (phi3)        | 3+           | 3x     |
| GPU      | No              | Sí (H200)    | ∞      |
| Costo    | $5-10/mes       | $0           | 100%   |

## Si Falla

### Modelos no aparecen

```bash
# Verificar Space está Running
curl https://TU_USUARIO-cognitia-ollama.hf.space/api/tags

# Si no responde, el Space puede estar sleeping
# Hacer request para despertar, esperar 30s

# Si responde pero Cognitia no muestra:
# Verificar URL exacta (sin / al final)
# Reiniciar Cognitia: railway up
```

### Latencia alta (>5s)

```bash
# Posibles causas:
# 1. Cold start del Space (primera request)
#    → Esperar y reintentar
# 2. Cuota ZeroGPU agotada
#    → Verificar en HF billing
# 3. Modelo muy grande
#    → Usar phi3 para tests rápidos
```

### Error "Model not found"

```bash
# Verificar nombre exacto del modelo
curl https://TU_USUARIO-cognitia-ollama.hf.space/api/tags | jq '.models[].name'

# Usar nombre exacto incluyendo tag
# Ejemplo: "qwen2.5:7b" no "qwen2.5"
```

### Solo admin ve modelos

```bash
# Verificar BYPASS_MODEL_ACCESS_CONTROL
railway variables | grep BYPASS

# Si no está, agregar:
railway variables set BYPASS_MODEL_ACCESS_CONTROL="true"
railway up
```

## Siguiente Paso

Si todos los criterios pasan: Continuar a [5.1-optimize-ejecutar.md](./5.1-optimize-ejecutar.md)

Si falla la conexión: Revisar troubleshooting y corregir.
