# Fase 6.1 - Ejecutar Cleanup y Documentación

## Objetivo

Finalizar la migración desactivando el servicio antiguo y documentando el nuevo setup.

## Contexto

- La migración está completa y funcionando
- El servicio Ollama en Railway ya no es necesario
- Se debe documentar el nuevo estado

## Prompt de Ejecución

```
Finaliza la migración con cleanup y documentación:

1. VERIFICAR QUE TODO FUNCIONA:

   # Test final de Cognitia
   # Abrir https://cognitia-production.up.railway.app
   # Enviar chat con cada modelo
   # Todo debe funcionar correctamente

2. DESACTIVAR OLLAMA EN RAILWAY (Recomendado):

   # Opción A - Pausar servicio (reversible, recomendado)
   a) Ir a Railway Dashboard
   b) Seleccionar servicio "ollama" o "ollama-service"
   c) Settings > "Pause Service"
   d) Confirmar

   # Opción B - Eliminar servicio (irreversible)
   a) Railway Dashboard > servicio ollama
   b) Settings > "Delete Service"
   c) Escribir nombre para confirmar

   # Opción C - Mantener como backup (costo extra)
   # No hacer nada, pero pagará ~$2-4/mes

3. ACTUALIZAR DOCUMENTACIÓN - RAILWAY_DEPLOY.md:

   # Editar el archivo de documentación
   cd /Users/juan.quiroga/Desktop/Estudio/MAIN/GIT/open-webui

   # Agregar sección sobre HF
   cat >> RAILWAY_DEPLOY.md << 'EOF'

## Ollama Service (Hugging Face)

A partir de 2026-02-15, el servicio Ollama se migró a Hugging Face Spaces con ZeroGPU.

### Configuración Actual

| Servicio | Plataforma | URL |
|----------|------------|-----|
| Cognitia App | Railway | https://cognitia-production.up.railway.app |
| Ollama | HF Spaces | https://[USUARIO]-cognitia-ollama.hf.space |

### Variables de Entorno (Railway)

```

OLLAMA_BASE_URL=https://[USUARIO]-cognitia-ollama.hf.space

```

### Modelos Disponibles

- qwen2.5:7b - Chat general y coding
- phi3 - Respuestas rápidas
- codellama:7b - Programación
- gemma2:9b - Razonamiento
- llama3.2:3b - Chat ligero
- mistral:7b - Versatilidad

### Hardware

- GPU: ZeroGPU (NVIDIA H200, ~70GB VRAM)
- Costo: $0 (free tier) o $9/mes (PRO)

### Mantenimiento

Para agregar modelos, editar `start.sh` en el repositorio HF:
https://huggingface.co/spaces/[USUARIO]/cognitia-ollama

EOF

4. ACTUALIZAR DOCUMENTACIÓN DE MIGRACIÓN:

   # Crear estado final
   cat > planning/migration-hf-ollama/ESTADO_FINAL.md << 'EOF'
# Estado Final de Migración

## Fecha
2026-02-15

## Resumen
Migración completada exitosamente de Railway a Hugging Face Spaces.

## Configuración Final

### Antes (Railway)
- Servicio: ollama-service
- Hardware: CPU
- Costo: $5-10/mes
- Modelos: phi3 (3.8B)
- Latencia: 2-5s

### Después (Hugging Face)
- Space: cognitia-ollama
- Hardware: ZeroGPU (H200)
- Costo: $0 (free) o $9 (PRO)
- Modelos: 6 (hasta 9B)
- Latencia: 0.5-2s

## Mejoras Logradas
- Latencia: 5x más rápido
- Modelos: 6x más modelos
- Costo: 100% ahorro (free tier)
- GPU: Disponible (vs ninguna)

## URLs
- Cognitia: https://cognitia-production.up.railway.app
- Ollama: https://[USUARIO]-cognitia-ollama.hf.space

## Próximos Pasos
- [ ] Monitorear uso de cuota ZeroGPU
- [ ] Evaluar upgrade a PRO si necesario
- [ ] Agregar más modelos según demanda
EOF

5. COMMIT DE DOCUMENTACIÓN:

   git add RAILWAY_DEPLOY.md planning/migration-hf-ollama/
   git commit -m "docs: Update documentation for HF Spaces migration"
   git push

6. CREAR BACKUP DE CONFIGURACIÓN:

   # Guardar configuración actual por si acaso
   mkdir -p ~/cognitia-backup-$(date +%Y%m%d)

   # Exportar variables de Railway
   railway variables > ~/cognitia-backup-$(date +%Y%m%d)/railway-vars.txt

   # Copiar archivos del Space
   cp -r ~/cognitia-ollama-space ~/cognitia-backup-$(date +%Y%m%d)/hf-space

7. NOTIFICAR EQUIPO (si aplica):

   # Enviar resumen a stakeholders:
   # - Nueva URL de Ollama
   # - Modelos disponibles
   # - Mejoras de performance
   # - Proceso de rollback si es necesario

Entrega:
- Servicio Railway Ollama desactivado/eliminado
- Documentación actualizada
- Backup de configuración
- Commit de documentación
```

## Checklist de Ejecución

```
RAILWAY CLEANUP
[ ] Servicio Ollama pausado o eliminado
[ ] Variables de Cognitia actualizadas (OLLAMA_BASE_URL)
[ ] Sin errores de conexión

DOCUMENTACIÓN
[ ] RAILWAY_DEPLOY.md actualizado
[ ] ESTADO_FINAL.md creado
[ ] Commit realizado
[ ] Push exitoso

BACKUP
[ ] Variables exportadas
[ ] Archivos del Space copiados
[ ] Backup guardado con fecha

VALIDACIÓN FINAL
[ ] Cognitia funciona con HF
[ ] Todos los modelos accesibles
[ ] Sin dependencias de Railway Ollama
```

## Decisión: Pausar vs Eliminar

| Opción       | Pros                       | Contras      | Costo    |
| ------------ | -------------------------- | ------------ | -------- |
| **Pausar**   | Reversible, fácil rollback | Ocupa slot   | $0       |
| **Eliminar** | Limpio, sin residuos       | Irreversible | $0       |
| **Mantener** | Backup activo              | Costo extra  | $2-4/mes |

**Recomendación**: Pausar por 1 semana, luego eliminar si todo funciona.

## Tiempo Estimado

| Paso               | Tiempo        |
| ------------------ | ------------- |
| Verificación final | 5 min         |
| Desactivar Railway | 2 min         |
| Documentación      | 10-15 min     |
| Backup             | 5 min         |
| **Total**          | **22-27 min** |

## Siguiente Paso

Continuar a [6.2-cleanup-validar.md](./6.2-cleanup-validar.md) para validación final.
