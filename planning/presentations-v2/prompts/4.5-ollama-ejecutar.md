# Etapa 4.5 - Ejecutar Despliegue de Ollama + Phi3

## Objetivo

Configurar un entorno de pruebas local con Ollama y el modelo Phi3 para validar seguridad y funcionamiento offline.

## Contexto

- Documento de referencia: [`../7-ollama-local-deployment.md`](../7-ollama-local-deployment.md)
- Modelo objetivo: Phi3 (3.8B parametros, ~2.3GB)

## Prompt de Ejecucion

```
Despliega Ollama con Phi3 para pruebas locales:

1. VERIFICAR REQUISITOS:

   # RAM disponible (minimo 8GB)
   # macOS:
   sysctl hw.memsize | awk '{print $2/1024/1024/1024 " GB"}'

   # Linux:
   free -h

   # Espacio en disco (minimo 10GB libres)
   df -h ~

2. INSTALAR OLLAMA:

   # macOS / Linux
   curl -fsSL https://ollama.com/install.sh | sh

   # Verificar instalacion
   ollama --version

   # Si ya esta instalado, verificar que esta actualizado
   ollama --version  # Deberia ser >= 0.3.x

3. INICIAR SERVICIO OLLAMA:

   # El servicio deberia iniciar automaticamente
   # Si no, iniciar manualmente:
   ollama serve &

   # Verificar que esta corriendo
   curl http://localhost:11434/api/tags
   # Deberia retornar JSON con modelos (puede estar vacio)

4. DESCARGAR PHI3:

   # Descargar modelo (puede tomar varios minutos)
   ollama pull phi3

   # Verificar descarga
   ollama list
   # Deberia mostrar: phi3:latest

5. TEST RAPIDO DE PHI3:

   # Probar que el modelo responde
   ollama run phi3 "Hola, responde en una linea: que es Python?"

   # Deberia responder algo como:
   # "Python es un lenguaje de programacion interpretado..."

6. CONFIGURAR OPEN WEBUI:

   # Opcion A: Variable de entorno (backend)
   export OLLAMA_BASE_URL=http://localhost:11434

   # Opcion B: Archivo .env
   echo "OLLAMA_BASE_URL=http://localhost:11434" >> .env

   # Reiniciar backend si estaba corriendo
   cd backend && ./dev.sh

7. VERIFICAR CONEXION EN UI:

   a) Abrir Open WebUI en navegador
   b) Ir a Settings > Connections
   c) Verificar que Ollama URL es http://localhost:11434
   d) Los modelos deberian aparecer automaticamente

8. CREAR CHAT DE PRUEBA:

   a) Seleccionar modelo "phi3" en el selector
   b) Enviar mensaje: "Hola, cual es tu nombre?"
   c) Verificar respuesta exitosa

9. OPCIONAL - DESCARGAR MODELOS ADICIONALES:

   # Llama 3.2 (mas rapido)
   ollama pull llama3.2

   # Mistral (mejor para razonamiento)
   ollama pull mistral

Entrega:
- Screenshot de ollama list
- Screenshot de Open WebUI con phi3 seleccionado
- Respuesta de prueba del modelo
```

## Comandos Rapidos

```bash
# Instalacion completa en una linea
curl -fsSL https://ollama.com/install.sh | sh && ollama pull phi3

# Verificar estado
ollama list && curl -s http://localhost:11434/api/tags | jq

# Test rapido
ollama run phi3 "Di hola en espanol"
```

## Checklist de Ejecucion

```
INSTALACION
[ ] Ollama instalado
[ ] Comando ollama disponible en PATH
[ ] Servicio corriendo en puerto 11434

MODELO
[ ] phi3 descargado (~2.3GB)
[ ] ollama list muestra phi3
[ ] Test de respuesta exitoso

OPEN WEBUI
[ ] OLLAMA_BASE_URL configurado
[ ] Backend reiniciado
[ ] Modelos visibles en selector
[ ] Chat con phi3 funciona

OPCIONAL
[ ] llama3.2 descargado
[ ] mistral descargado
```

## Troubleshooting

### Ollama no inicia

```bash
# Verificar si ya esta corriendo
pgrep ollama

# Matar proceso existente si hay problemas
pkill ollama

# Reiniciar
ollama serve
```

### Modelo no descarga

```bash
# Verificar espacio
df -h ~/.ollama

# Limpiar cache si es necesario
rm -rf ~/.ollama/models/blobs/*

# Reintentar
ollama pull phi3
```

### Open WebUI no detecta modelos

```bash
# Verificar URL
curl http://localhost:11434/api/tags

# Verificar variable de entorno
echo $OLLAMA_BASE_URL

# Reiniciar backend
cd backend && ./dev.sh
```

## Tiempo Estimado

| Paso                  | Tiempo                         |
| --------------------- | ------------------------------ |
| Instalar Ollama       | 1-2 min                        |
| Descargar Phi3        | 5-15 min (depende de internet) |
| Configurar Open WebUI | 2-3 min                        |
| Tests                 | 5 min                          |
| **Total**             | **15-25 min**                  |

## Siguiente Paso

Continuar a 4.5-ollama-validar.md para pruebas de seguridad.
