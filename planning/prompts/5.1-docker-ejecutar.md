# Prompt 5.1 - Crear Sistema Docker White-Label

> **Etapa**: 5 - Docker Build
> **Tipo**: Ejecucion
> **Siguiente**: [5.2-docker-validar.md](./5.2-docker-validar.md)

---

## Prompt

```text
**Rol**: DevOps / Ingeniero de Infraestructura
**Contexto**: Crear sistema de build Docker personalizado para marca blanca

**Tarea**: Crear Dockerfile y docker-compose para builds personalizados

**Pasos**:

1. **Crear Dockerfile.whitelabel**:

```dockerfile
# ==============================================================================
# Dockerfile.whitelabel - Build de marca blanca
# ==============================================================================
ARG NODE_VERSION=22
ARG PYTHON_VERSION=3.11.14

# ============================================
# STAGE 1: Frontend Build
# ============================================
FROM node:${NODE_VERSION}-alpine3.20 AS frontend

WORKDIR /app

ARG BRAND_NAME="Cognitia"
ENV BRAND_NAME=${BRAND_NAME}

COPY package*.json ./
RUN npm ci --ignore-scripts

COPY . .
RUN npm run build

# ============================================
# STAGE 2: Python Runtime
# ============================================
FROM python:${PYTHON_VERSION}-slim-bookworm AS runtime

ARG USE_CUDA=false
ARG USE_CUDA_VER=cu128
ARG BUILD_HASH=dev
ARG BRAND_NAME="Cognitia"

ENV PYTHONUNBUFFERED=1 \
    PORT=8080 \
    ENV=prod \
    WEBUI_NAME="${BRAND_NAME}" \
    BUILD_HASH=${BUILD_HASH} \
    SCARF_NO_ANALYTICS=true \
    DO_NOT_TRACK=true \
    ANONYMIZED_TELEMETRY=false

WORKDIR /app

RUN apt-get update && apt-get install -y --no-install-recommends \
    git build-essential pandoc gcc netcat-openbsd curl jq \
    ffmpeg libsm6 libxext6 python3-dev \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

RUN pip install --no-cache-dir uv

COPY backend/requirements.txt /app/backend/
WORKDIR /app/backend
RUN uv pip install --system --no-cache -r requirements.txt

COPY backend/ /app/backend/
COPY --from=frontend /app/build /app/build
COPY --from=frontend /app/static /app/static

RUN mkdir -p /app/backend/data

HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -sf http://localhost:${PORT}/health | jq -e '.status == true' || exit 1

EXPOSE ${PORT}

CMD ["python", "-m", "uvicorn", "open_webui.main:app", "--host", "0.0.0.0", "--port", "8080", "--forwarded-allow-ips", "*"]
```

2. **Crear docker-compose.whitelabel.yaml**:

```yaml
version: "3.8"

services:
  whitelabel-ai:
    build:
      context: .
      dockerfile: Dockerfile.whitelabel
      args:
        BRAND_NAME: ${BRAND_NAME:-Cognitia}
        USE_CUDA: ${USE_CUDA:-false}
        BUILD_HASH: ${BUILD_HASH:-dev}
    image: ${REGISTRY:-local}/cognitia-ai:${VERSION:-latest}
    container_name: cognitia-ai
    restart: unless-stopped
    environment:
      - WEBUI_NAME=${BRAND_NAME:-Cognitia}
      - WEBUI_SECRET_KEY=${SECRET_KEY:-}
      - OLLAMA_BASE_URL=${OLLAMA_URL:-http://ollama:11434}
      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ENABLE_SIGNUP=${ENABLE_SIGNUP:-true}
      - DEFAULT_USER_ROLE=${DEFAULT_USER_ROLE:-pending}
    ports:
      - "${PORT:-3000}:8080"
    volumes:
      - cognitia-data:/app/backend/data
    networks:
      - cognitia-network
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    container_name: cognitia-ollama
    restart: unless-stopped
    volumes:
      - ollama-models:/root/.ollama
    networks:
      - cognitia-network

volumes:
  cognitia-data:
    name: cognitia-data
  ollama-models:
    name: cognitia-ollama-models

networks:
  cognitia-network:
    name: cognitia-network
    driver: bridge
```

3. **Crear scripts/build-whitelabel.sh**:

```bash
#!/bin/bash
set -e

BRAND_NAME="${BRAND_NAME:-Cognitia}"
VERSION="${VERSION:-$(git describe --tags --always 2>/dev/null || echo 'dev')}"
REGISTRY="${REGISTRY:-local}"
USE_CUDA="${USE_CUDA:-false}"

echo "=============================================="
echo "  Building: ${BRAND_NAME}"
echo "  Version:  ${VERSION}"
echo "  Registry: ${REGISTRY}"
echo "  CUDA:     ${USE_CUDA}"
echo "=============================================="

docker build \
  --build-arg BRAND_NAME="${BRAND_NAME}" \
  --build-arg BUILD_HASH="$(git rev-parse --short HEAD 2>/dev/null || echo 'dev')" \
  --build-arg USE_CUDA="${USE_CUDA}" \
  -f Dockerfile.whitelabel \
  -t "${REGISTRY}/cognitia-ai:${VERSION}" \
  -t "${REGISTRY}/cognitia-ai:latest" \
  .

echo ""
echo "Build complete: ${REGISTRY}/cognitia-ai:${VERSION}"
echo ""
echo "To run: docker-compose -f docker-compose.whitelabel.yaml up -d"
```

4. **Hacer script ejecutable**:
   chmod +x scripts/build-whitelabel.sh

5. **Crear .env.whitelabel.example**:

```env
# Branding
BRAND_NAME=Cognitia

# Build
VERSION=1.0.0
REGISTRY=local
USE_CUDA=false

# Runtime
PORT=3000
SECRET_KEY=your-secret-key-here
ENABLE_SIGNUP=true
DEFAULT_USER_ROLE=pending

# LLM Providers
OLLAMA_URL=http://ollama:11434
OPENAI_API_BASE_URL=
OPENAI_API_KEY=
```

**Archivos a crear**:
- Dockerfile.whitelabel
- docker-compose.whitelabel.yaml
- scripts/build-whitelabel.sh
- .env.whitelabel.example
```

---

## Variables a Reemplazar

Antes de ejecutar, reemplazar:
- `Cognitia` → Nombre completo
- `cognitia` → Nombre corto lowercase

## Archivos a Crear

| Archivo | Descripcion |
|---------|-------------|
| `Dockerfile.whitelabel` | Multi-stage build |
| `docker-compose.whitelabel.yaml` | Orchestration |
| `scripts/build-whitelabel.sh` | Build script |
| `.env.whitelabel.example` | Environment template |
